{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libnetcdf.so.7: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a25a31e9bd12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclick\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnetCDF4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/simonaoliver/venvs/py35/lib/python3.5/site-packages/netCDF4/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# init for netCDF4. package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Docstring comes from extension module _netCDF4.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_netCDF4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Need explicit imports for names beginning with underscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_netCDF4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__pdoc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libnetcdf.so.7: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "\"\"\"\n",
    "Ingest data from the command-line.\n",
    "\n",
    "python srtm_prepare.py --output Elevation_1secSRTM_DEMs_v1.0_DEM_Mosaic_dem1sv1_0.yaml /g/data/rr1/Elevation/NetCDF/1secSRTM_DEMs_v1.0/DEM/Elevation_1secSRTM_DEMs_v1.0_DEM_Mosaic_dem1sv1_0.nc\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import uuid\n",
    "from dateutil.parser import parse\n",
    "import yaml\n",
    "import click\n",
    "import netCDF4\n",
    "import os\n",
    "def prepare_layers(images):\n",
    "    layerdict={}\n",
    "    for i in images:\n",
    "        image = netCDF4.Dataset(i)\n",
    "        layerpath = str(image.filepath())\n",
    "        for targetlayer in image.variables.values():\n",
    "            if targetlayer.name not in ['crs', 'lat', 'lon']:\n",
    "                layername = str(targetlayer.name)\n",
    "                layerdict[layername]= {'path': layerpath,'layer': layername,}\n",
    "    return layerdict\n",
    "\n",
    "def prepare_dataset(image, datasets):\n",
    "\n",
    "    image = netCDF4.Dataset(image)\n",
    "    print(image.variables.values)\n",
    "    projection = str(image.geospatial_bounds_crs)\n",
    "    left, right = float(image.geospatial_lon_min), float(image.geospatial_lon_max)\n",
    "    bottom, top = float(image.geospatial_lat_min), float(image.geospatial_lat_max)\n",
    "\n",
    "    return {\n",
    "        'id': str(uuid.uuid4()),\n",
    "        'processing_level': 'modelled',\n",
    "        'product_type': 'DEM',\n",
    "        'creation_dt': parse(image.date_created).isoformat(),\n",
    "        'platform': {'code': 'Space Shuttle Endeavour'},\n",
    "        'instrument': {'name': 'SIR'},\n",
    "        'extent': {\n",
    "            'coord': {\n",
    "                'ul': {'lon': left, 'lat': top},\n",
    "                'ur': {'lon': right, 'lat': top},\n",
    "                'll': {'lon': left, 'lat': bottom},\n",
    "                'lr': {'lon': right, 'lat': bottom},\n",
    "            },\n",
    "            'from_dt': parse(image.date_created).isoformat(), \n",
    "            'to_dt': parse(image.date_created).isoformat(),\n",
    "            'center_dt': parse(image.date_created).isoformat(),\n",
    "        },\n",
    "        'format': {'name': 'NETCDF'},\n",
    "        'grid_spatial': {\n",
    "            'projection': {\n",
    "                'spatial_reference': projection,\n",
    "                'geo_ref_points': {\n",
    "                    'ul': {'x': left, 'y': top},\n",
    "                    'ur': {'x': right, 'y': top},\n",
    "                    'll': {'x': left, 'y': bottom},\n",
    "                    'lr': {'x': right, 'y': bottom},\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'image': {\n",
    "            'bands': prepare_layers(datasets)\n",
    "        },\n",
    "        'lineage': {'source_datasets': {}},\n",
    "    }\n",
    "\n",
    "\n",
    "#@click.command(help=\"Prepare single layer netcdf with common grid spec for ingestion to Data Cube.\")\n",
    "#@click.argument('datasets', type=click.Path(exists=True, readable=True),nargs=-1)\n",
    "#@click.option('--output', help=\"Write datasets into this file\", type=click.Path(exists=False, writable=True))\n",
    "datasets = '--output srtmdem.yaml /media/simonaoliver/datacube/input/SRTM/DEM-H/Elevation_1secSRTM_DEMs_v1.0_DEM-H_FlowDirectionTiles_e113s23flwdir.nc'\n",
    "output = 'srtm.yaml'\n",
    "def main(datasets, output):\n",
    "    with open(output, 'w') as stream:\n",
    "        yaml.dump((prepare_dataset(datasets[0], datasets)),stream)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
