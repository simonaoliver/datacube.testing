{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:GDAL:CPLE_OpenFailed in `LC80960852015365-SC20160211222236.tar.gz' does not exist in the file system,\n",
      "and is not recognised as a supported dataset name.\n",
      "\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "`LC80960852015365-SC20160211222236.tar.gz' does not exist in the file system,\nand is not recognised as a supported dataset name.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-46ab248bd65e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0msafe_valid_region\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/home/simonaoliver/data/USGS_SR/LC80960852015365-SC20160211222236/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;31m###END IMAGE BOUNDARY CODE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-46ab248bd65e>\u001b[0m in \u001b[0;36msafe_valid_region\u001b[1;34m(images, mask_value)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msafe_valid_region\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalid_region\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRasterioIOError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-46ab248bd65e>\u001b[0m in \u001b[0;36mvalid_region\u001b[1;34m(images, mask_value)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;31m## ensure formats match\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/simonaoliver/venvs/agdc-v2/local/lib/python2.7/site-packages/rasterio/__init__.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, driver, width, height, count, crs, transform, dtype, nodata, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         raise ValueError(\n\u001b[0;32m    122\u001b[0m             \"mode string must be one of 'r', 'r+', or 'w', not %s\" % mode)\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetReader.start (rasterio/_base.c:2615)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mrasterio/_err.pyx\u001b[0m in \u001b[0;36mrasterio._err.GDALErrCtxManager.__exit__ (rasterio/_err.c:994)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: `LC80960852015365-SC20160211222236.tar.gz' does not exist in the file system,\nand is not recognised as a supported dataset name.\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "\"\"\"\n",
    "Ingest data from the command-line.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import, division\n",
    "\n",
    "import logging\n",
    "import uuid\n",
    "from xml.etree import ElementTree\n",
    "import re\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from dateutil import parser\n",
    "from datetime import timedelta\n",
    "import rasterio.warp\n",
    "import click\n",
    "from osgeo import osr\n",
    "import os\n",
    "# image boundary imports\n",
    "import rasterio\n",
    "from rasterio.errors import RasterioIOError\n",
    "import rasterio.features\n",
    "import shapely.affinity\n",
    "import shapely.geometry\n",
    "import shapely.ops\n",
    "\n",
    "_STATIONS = {'023': 'TKSC', '022': 'SGS', '010': 'GNC', '011': 'HOA',\n",
    "             '012': 'HEOC', '013': 'IKR', '014': 'KIS', '015': 'LGS',\n",
    "             '016': 'MGR', '017': 'MOR', '032': 'LGN', '019': 'MTI', '030': 'KHC',\n",
    "             '031': 'MLK', '018': 'MPS', '003': 'BJC', '002': 'ASN', '001': 'AGS',\n",
    "             '007': 'DKI', '006': 'CUB', '005': 'CHM', '004': 'BKT', '009': 'GLC',\n",
    "             '008': 'EDC', '029': 'JSA', '028': 'COA', '021': 'PFS', '020': 'PAC'}\n",
    "\n",
    "###IMAGE BOUNDARY CODE\n",
    "\n",
    "def safe_valid_region(images, mask_value=None):\n",
    "    try:\n",
    "        return valid_region(images, mask_value)\n",
    "    except (OSError, RasterioIOError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def valid_region(images, mask_value=None):\n",
    "    mask = None\n",
    "\n",
    "    for fname in images:\n",
    "        ## ensure formats match\n",
    "        with rasterio.open(str(fname), 'r') as ds:\n",
    "            transform = ds.affine\n",
    "            img = ds.read(1)\n",
    "\n",
    "            if mask_value is not None:\n",
    "                new_mask = img & mask_value == mask_value\n",
    "            else:\n",
    "                new_mask = img != ds.nodata\n",
    "\n",
    "            if mask is None:\n",
    "                mask = new_mask\n",
    "            else:\n",
    "                mask |= new_mask\n",
    "\n",
    "    shapes = rasterio.features.shapes(mask.astype('uint8'), mask=mask)\n",
    "    shape = shapely.ops.unary_union([shapely.geometry.shape(shape) for shape, val in shapes if val == 1])\n",
    "\n",
    "    # convex hull\n",
    "    geom = shape.convex_hull\n",
    "\n",
    "    # buffer by 1 pixel\n",
    "    geom = geom.buffer(1, join_style=3, cap_style=3)\n",
    "\n",
    "    # simplify with 1 pixel radius\n",
    "    geom = geom.simplify(1)\n",
    "\n",
    "    # intersect with image bounding box\n",
    "    geom = geom.intersection(shapely.geometry.box(0, 0, mask.shape[1], mask.shape[0]))\n",
    "\n",
    "    # transform from pixel space into CRS space\n",
    "    geom = shapely.affinity.affine_transform(geom, (transform.a, transform.b, transform.d,\n",
    "                                                    transform.e, transform.xoff, transform.yoff))\n",
    "\n",
    "    output = shapely.geometry.mapping(geom)\n",
    "    output['coordinates'] = _to_lists(output['coordinates'])\n",
    "    return output\n",
    "\n",
    "\n",
    "def _to_lists(x):\n",
    "    \"\"\"\n",
    "    Returns lists of lists when given tuples of tuples\n",
    "    \"\"\"\n",
    "    if isinstance(x, tuple):\n",
    "        return [_to_lists(el) for el in x]\n",
    "\n",
    "    return x\n",
    "\n",
    "print safe_valid_region(os.listdir('/home/simonaoliver/data/USGS_SR/LC80960852015365-SC20160211222236/'))\n",
    "###END IMAGE BOUNDARY CODE\n",
    "\n",
    "def band_name(path):\n",
    "    name = path.stem\n",
    "    position = name.find('_')\n",
    "\n",
    "    if position == -1:\n",
    "        raise ValueError('Unexpected tif image in eods: %r' % path)\n",
    "    if re.match(r\"[Bb]\\d+\", name[position+1:]):\n",
    "        layername = name[position+2:]\n",
    "\n",
    "    else:\n",
    "        layername = name[position+1:]\n",
    "    return layername\n",
    "\n",
    "\n",
    "def get_projection(path):\n",
    "    with rasterio.open(str(path)) as img:\n",
    "        left, bottom, right, top = img.bounds\n",
    "        return {\n",
    "            'spatial_reference': str(img.crs_wkt),\n",
    "            'geo_ref_points': {\n",
    "                'ul': {'x': left, 'y': top},\n",
    "                'ur': {'x': right, 'y': top},\n",
    "                'll': {'x': left, 'y': bottom},\n",
    "                'lr': {'x': right, 'y': bottom},\n",
    "                }\n",
    "        }\n",
    "\n",
    "\n",
    "def get_coords(geo_ref_points, spatial_ref):\n",
    "    spatial_ref = osr.SpatialReference(spatial_ref)\n",
    "    t = osr.CoordinateTransformation(spatial_ref, spatial_ref.CloneGeogCS())\n",
    "\n",
    "    def transform(p):\n",
    "        lon, lat, z = t.TransformPoint(p['x'], p['y'])\n",
    "        return {'lon': lon, 'lat': lat}\n",
    "    return {key: transform(p) for key, p in geo_ref_points.items()}\n",
    "\n",
    "\n",
    "def populate_coord(doc):\n",
    "    proj = doc['grid_spatial']['projection']\n",
    "    doc['extent']['coord'] = get_coords(proj['geo_ref_points'], proj['spatial_reference'])\n",
    "\n",
    "\n",
    "def crazy_parse(timestr):\n",
    "    try:\n",
    "        return parser.parse(timestr)\n",
    "    except ValueError:\n",
    "        if not timestr[-2:] == \"60\":\n",
    "            raise\n",
    "        return parser.parse(timestr[:-2]+'00') + timedelta(minutes=1)\n",
    "\n",
    "\n",
    "def prep_dataset(fields, path):\n",
    "\n",
    "    for file in os.listdir(str(path)):\n",
    "        if file.endswith(\".xml\") and (not file.endswith('aux.xml')):\n",
    "            metafile = file\n",
    "    # Parse xml ElementTree gives me a headache so using lxml\n",
    "    doc = ElementTree.parse(os.path.join(str(path), metafile))\n",
    "    #TODO root method doesn't work here - need to include xlmns...\n",
    "\n",
    "    for global_metadata in doc.findall('{http://espa.cr.usgs.gov/v1.2}global_metadata'):\n",
    "        satellite = (global_metadata.find('{http://espa.cr.usgs.gov/v1.2}satellite')).text\n",
    "        instrument = (global_metadata.find('{http://espa.cr.usgs.gov/v1.2}instrument')).text\n",
    "        acquisition_date = str((global_metadata.find('{http://espa.cr.usgs.gov/v1.2}acquisition_date')).text).replace(\"-\",\"\")\n",
    "        scene_center_time = (global_metadata.find('{http://espa.cr.usgs.gov/v1.2}scene_center_time')).text[:8]\n",
    "        center_dt = crazy_parse(acquisition_date+\"T\"+scene_center_time)\n",
    "        aos = crazy_parse(acquisition_date+\"T\"+scene_center_time)-timedelta(seconds=(24/2))\n",
    "        los = aos + timedelta(seconds=24)\n",
    "        lpgs_metadata_file = (global_metadata.find('{http://espa.cr.usgs.gov/v1.2}lpgs_metadata_file')).text\n",
    "        groundstation = lpgs_metadata_file[16:19]\n",
    "        fields.update({'instrument': instrument, 'satellite': satellite})\n",
    "\n",
    "\n",
    "    start_time = aos\n",
    "    end_time = los\n",
    "    images = {band_name(im_path): {\n",
    "        'path': str(im_path.relative_to(path))\n",
    "    } for im_path in path.glob('*.tif')}\n",
    "\n",
    "    doc = {\n",
    "        'id': str(uuid.uuid4()),\n",
    "        'processing_level': fields[\"level\"],\n",
    "        'product_type': fields[\"type\"],\n",
    "        'creation_dt':  fields[\"creation_dt\"],\n",
    "        'platform': {'code': fields[\"satellite\"]},\n",
    "        'instrument': {'name': fields[\"instrument\"]},\n",
    "        'acquisition': {\n",
    "            'groundstation': {\n",
    "                'name': groundstation,\n",
    "                'aos': str(aos),\n",
    "                'los': str(los)\n",
    "            }\n",
    "        },\n",
    "        'extent': {\n",
    "            'from_dt': str(start_time),\n",
    "            'to_dt': str(end_time),\n",
    "            'center_dt': str(center_dt)\n",
    "        },\n",
    "        'format': {'name': 'GeoTiff'},\n",
    "        'grid_spatial': {\n",
    "            'projection': get_projection(path/next(iter(images.values()))['path'])\n",
    "        },\n",
    "        'image': {\n",
    "            'satellite_ref_point_start': {'path': int(fields[\"path\"]), 'row': int(fields[\"row\"])},\n",
    "            'satellite_ref_point_end': {'path': int(fields[\"path\"]), 'row': int(fields[\"row\"])},\n",
    "            'bands': images\n",
    "        },\n",
    "        'valid_data': str(safe_valid_region(os.listdir([path]))),        #TODO include 'lineage': {'source_datasets': {'lpgs_metadata_file': lpgs_metadata_file}}\n",
    "        'lineage': {'source_datasets': {}}\n",
    "    }\n",
    "    populate_coord(doc)\n",
    "    return doc\n",
    "\n",
    "\n",
    "def dataset_folder(fields):\n",
    "    fmt_str = \"{vehicle}_{instrument}_{type}_{level}_GA{type}{product}-{groundstation}_{path}_{row}_{date}\"\n",
    "    return fmt_str.format(**fields)\n",
    "\n",
    "\n",
    "def prepare_datasets(nbar_path):\n",
    "\n",
    "    fields = re.match(\n",
    "        (\n",
    "            r\"(?P<code>LC8|LE7|LT5)\"\n",
    "            r\"(?P<path>[0-9]{3})\"\n",
    "            r\"(?P<row>[0-9]{3})\"\n",
    "            r\"(?P<productyear>[0-9]{4})\"\n",
    "            r\"(?P<julianday>[0-9]{3})\"\n",
    "\n",
    "        ), nbar_path.stem).groupdict()\n",
    "\n",
    "    timedelta(days=int(fields[\"julianday\"]))\n",
    "    fields.update({'level': 'sr_refl', 'type': 'LEDAPS', 'creation_dt': ((crazy_parse(fields[\"productyear\"]+'0101T00:00:00'))+timedelta(days=int(fields[\"julianday\"])))})\n",
    "    nbar = prep_dataset(fields, nbar_path)\n",
    "    return (nbar, nbar_path)\n",
    "\n",
    "datasets = ['/home/simonaoliver/data/USGS_SR/LC80960852015365-SC20160211222236/']\n",
    "for dataset in datasets:\n",
    "    path = Path(dataset)\n",
    "    print path\n",
    "    logging.info(\"Processing %s\", path)\n",
    "    documents = prepare_datasets(path)\n",
    "\n",
    "    dataset, folder = documents\n",
    "    yaml_path = str(folder.joinpath('agdc-metadata.yaml'))\n",
    "    logging.info(\"Writing %s\", yaml_path)\n",
    "    with open(yaml_path, 'w') as stream:\n",
    "        yaml.dump(dataset, stream)\n",
    "\n",
    "#@click.command(help=\"Prepare USGS LS dataset for ingestion into the Data Cube.\")\n",
    "#@click.argument('datasets',\n",
    "#                type=click.Path(exists=True, readable=True, writable=True),\n",
    "#                nargs=-1)\n",
    "#def main(datasets):\n",
    "#    logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s', level=logging.INFO)#\n",
    "\n",
    "#    for dataset in datasets:\n",
    "#        path = Path(dataset)#\n",
    "#\n",
    "#        logging.info(\"Processing %s\", path)\n",
    "#        documents = prepare_datasets(path)#\n",
    "#\n",
    "#        dataset, folder = documents\n",
    "#        yaml_path = str(folder.joinpath('agdc-metadata.yaml'))\n",
    "#        logging.info(\"Writing %s\", yaml_path)\n",
    "#        with open(yaml_path, 'w') as stream:\n",
    "#            yaml.dump(dataset, stream)\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
